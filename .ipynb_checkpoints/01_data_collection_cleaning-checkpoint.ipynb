{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase One: Data Collection & Cleaning\n",
    "## Portfolio Management PPI Modeling Project\n",
    "\n",
    "**Objective**: Collect and clean data for forecasting month-on-month percentage changes in PPI for portfolio management services (PPIDF01 Index).\n",
    "\n",
    "**Key Data Sources**:\n",
    "- Primary Target: PPIDF01 Index (PPI Portfolio Management, NSA) from FRED\n",
    "- Market Returns: S&P 500, NASDAQ, Russell 2000, VIX\n",
    "- Bond Markets: Treasury yields, corporate spreads\n",
    "- Macro Indicators: Dollar index, commodities, employment data\n",
    "\n",
    "**Technical Stack**: Polars for data manipulation, FRED API, caching system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Import our data collection module\n",
    "from data_collection import DataCollector\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"Polars version: {pl.__version__}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Key Configuration\n",
    "\n",
    "**Important**: You need to get a FRED API key from https://fred.stlouisfed.org/docs/api/api_key.html\n",
    "\n",
    "1. Create a `.env` file in the project root\n",
    "2. Add your API key: `FRED_API_KEY=your_key_here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if FRED API key is configured\n",
    "fred_key = os.getenv('FRED_API_KEY')\n",
    "if fred_key:\n",
    "    print(\"✓ FRED API key configured\")\n",
    "    print(f\"Key starts with: {fred_key[:8]}...\")\n",
    "else:\n",
    "    print(\"⚠️  FRED API key not found!\")\n",
    "    print(\"Please set FRED_API_KEY in your .env file\")\n",
    "    print(\"Get your key from: https://fred.stlouisfed.org/docs/api/api_key.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data collector\n",
    "collector = DataCollector(cache_dir=\"data_cache\")\n",
    "\n",
    "print(\"Data collector initialized with caching enabled\")\n",
    "print(f\"Cache directory: {collector.cache_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Collect Target Variable\n",
    "### PPIDF01 Index - PPI Portfolio Management (NSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the primary target variable\n",
    "try:\n",
    "    target_data = collector.get_target_variable()\n",
    "    print(f\"Target data shape: {target_data.shape}\")\n",
    "    print(f\"Date range: {target_data['date'].min()} to {target_data['date'].max()}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(target_data.head())\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nBasic statistics:\")\n",
    "    print(target_data.select(pl.col('value').describe()))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching target data: {e}\")\n",
    "    target_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collect Market Returns Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch market returns data\n",
    "try:\n",
    "    market_data = collector.get_market_returns_data()\n",
    "    \n",
    "    print(\"Market data collected:\")\n",
    "    for name, df in market_data.items():\n",
    "        if isinstance(df, pl.DataFrame):\n",
    "            print(f\"  {name}: {df.shape} - Range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    if 'SP500' in market_data:\n",
    "        print(\"\\nS&P 500 sample data:\")\n",
    "        print(market_data['SP500'].head())\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching market data: {e}\")\n",
    "    market_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Collect Bond Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch bond market data\n",
    "try:\n",
    "    bond_data = collector.get_bond_market_data()\n",
    "    \n",
    "    print(\"Bond market data collected:\")\n",
    "    for name, df in bond_data.items():\n",
    "        if isinstance(df, pl.DataFrame):\n",
    "            print(f\"  {name}: {df.shape} - Range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    if 'DGS10' in bond_data:\n",
    "        print(\"\\n10-Year Treasury sample data:\")\n",
    "        print(bond_data['DGS10'].head())\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching bond data: {e}\")\n",
    "    bond_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Collect Macro Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch macro indicators\n",
    "try:\n",
    "    macro_data = collector.get_macro_indicators()\n",
    "    \n",
    "    print(\"Macro indicators collected:\")\n",
    "    for name, df in macro_data.items():\n",
    "        if isinstance(df, pl.DataFrame):\n",
    "            print(f\"  {name}: {df.shape} - Range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    if 'DTWEXBGS' in macro_data:\n",
    "        print(\"\\nDollar Index sample data:\")\n",
    "        print(macro_data['DTWEXBGS'].head())\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error fetching macro data: {e}\")\n",
    "    macro_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_data_quality(df: pl.DataFrame, name: str) -> dict:\n",
    "    \"\"\"Assess data quality for a given DataFrame.\"\"\"\n",
    "    if df is None or df.height == 0:\n",
    "        return {\"name\": name, \"status\": \"empty\", \"issues\": [\"No data available\"]}\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    # Check for missing values\n",
    "    null_count = df.null_count().sum_horizontal()[0]\n",
    "    if null_count > 0:\n",
    "        issues.append(f\"Missing values: {null_count}\")\n",
    "    \n",
    "    # Check date range\n",
    "    date_range = df['date'].max() - df['date'].min()\n",
    "    if date_range.days < 365:\n",
    "        issues.append(f\"Short time series: {date_range.days} days\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicate_count = df.height - df.unique().height\n",
    "    if duplicate_count > 0:\n",
    "        issues.append(f\"Duplicate rows: {duplicate_count}\")\n",
    "    \n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"rows\": df.height,\n",
    "        \"date_range\": f\"{df['date'].min()} to {df['date'].max()}\",\n",
    "        \"issues\": issues if issues else [\"No issues detected\"]\n",
    "    }\n",
    "\n",
    "# Assess all collected data\n",
    "quality_report = []\n",
    "\n",
    "if target_data is not None:\n",
    "    quality_report.append(assess_data_quality(target_data, \"PPIDF01 (Target)\"))\n",
    "\n",
    "for category, data_dict in [(\"Market\", market_data), (\"Bond\", bond_data), (\"Macro\", macro_data)]:\n",
    "    for name, df in data_dict.items():\n",
    "        if isinstance(df, pl.DataFrame):\n",
    "            quality_report.append(assess_data_quality(df, f\"{category}: {name}\"))\n",
    "\n",
    "# Display quality report\n",
    "print(\"DATA QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 50)\n",
    "for report in quality_report:\n",
    "    print(f\"\\n{report['name']}:\")\n",
    "    print(f\"  Rows: {report.get('rows', 'N/A')}\")\n",
    "    print(f\"  Range: {report.get('date_range', 'N/A')}\")\n",
    "    print(f\"  Issues: {', '.join(report['issues'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Initial Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot target variable if available\n",
    "if target_data is not None and target_data.height > 0:\n",
    "    # Convert to pandas for plotting\n",
    "    target_pd = target_data.to_pandas()\n",
    "    target_pd['date'] = pd.to_datetime(target_pd['date'])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    # Time series plot\n",
    "    ax1.plot(target_pd['date'], target_pd['value'], linewidth=2, color='navy')\n",
    "    ax1.set_title('PPI Portfolio Management (PPIDF01) - NSA', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Index Value')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Calculate month-over-month percentage change\n",
    "    target_pd['mom_pct'] = target_pd['value'].pct_change() * 100\n",
    "    \n",
    "    # MoM percentage change plot\n",
    "    ax2.plot(target_pd['date'], target_pd['mom_pct'], linewidth=1.5, color='darkred', alpha=0.7)\n",
    "    ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    ax2.set_title('Month-over-Month Percentage Change (Target Variable)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('MoM % Change')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics for MoM changes\n",
    "    mom_stats = target_pd['mom_pct'].describe()\n",
    "    print(\"\\nMonth-over-Month % Change Statistics:\")\n",
    "    print(mom_stats)\n",
    "    \n",
    "else:\n",
    "    print(\"Target data not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all data into a single structure\n",
    "all_collected_data = {\n",
    "    'target': target_data,\n",
    "    'market_returns': market_data,\n",
    "    'bond_market': bond_data,\n",
    "    'macro_indicators': macro_data\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "try:\n",
    "    collector.save_collected_data(all_collected_data, \"phase_one_collected_data.json\")\n",
    "    print(\"✓ All data saved successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving data: {e}\")\n",
    "\n",
    "# Create summary report\n",
    "summary = {\n",
    "    'collection_date': datetime.now().isoformat(),\n",
    "    'target_variable': 'PPIDF01 - PPI Portfolio Management (NSA)',\n",
    "    'data_sources': {\n",
    "        'target': 1 if target_data is not None else 0,\n",
    "        'market_returns': len(market_data),\n",
    "        'bond_market': len(bond_data),\n",
    "        'macro_indicators': len(macro_data)\n",
    "    },\n",
    "    'total_series': 1 + len(market_data) + len(bond_data) + len(macro_data)\n",
    "}\n",
    "\n",
    "print(\"\\nPHASE ONE COMPLETION SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Collection Date: {summary['collection_date']}\")\n",
    "print(f\"Target Variable: {summary['target_variable']}\")\n",
    "print(f\"Total Series Collected: {summary['total_series']}\")\n",
    "print(\"\\nData Sources:\")\n",
    "for source, count in summary['data_sources'].items():\n",
    "    print(f\"  {source.replace('_', ' ').title()}: {count} series\")\n",
    "\n",
    "print(\"\\n✓ Phase One: Data Collection Strategy - COMPLETE\")\n",
    "print(\"Next: Phase Two - Exploratory Data Analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
